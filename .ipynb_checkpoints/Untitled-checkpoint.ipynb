{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 60000\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "----- FNN configuration -----\n",
    "input data: MNIST dataset, images of hand written digits from 0 to 9\n",
    "output: prediction of digits 0 to 9\n",
    "\n",
    "input layer: 784 (from 28 * 28 images)\n",
    "hidden layer: 1024\n",
    "output layer: 10 (prediction of digit 0~9)\n",
    "\n",
    "activation function for hidden layer: relu\n",
    "activation function for output layer: softmax\n",
    "\n",
    "loss function: cross-entropy loss\n",
    "optimizer: mini-batch gradient descent\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def read_MNIST_image(filename = 'train-images.idx3-ubyte'):\n",
    "    file = open(filename, 'rb')\n",
    "    magic_number = struct.unpack('>I', file.read(4))[0]\n",
    "    image_number = struct.unpack('>I', file.read(4))[0]\n",
    "    row = struct.unpack('>I', file.read(4))[0]\n",
    "    col = struct.unpack('>I', file.read(4))[0]\n",
    "    piexl_number = row*col\n",
    "\n",
    "    image_set = np.zeros((image_number,row,col))\n",
    "    \n",
    "    for idx in range(image_number):\n",
    "        img = np.frombuffer(file.read(piexl_number), dtype=np.uint8, count=piexl_number)\n",
    "        image_set[idx] = img.reshape((row,col))\n",
    "        \n",
    "    return image_set\n",
    "\n",
    "\n",
    "def read_MNIST_label(filename = 'train-labels.idx1-ubyte'):\n",
    "    file = open(filename, 'rb')\n",
    "    magic_number = struct.unpack('>I', file.read(4))[0]\n",
    "    label_number = struct.unpack('>I', file.read(4))[0]\n",
    "    print(\"Label: %d\"%label_number)\n",
    "\n",
    "    label_set = np.zeros((label_number,1), dtype=np.uint8)\n",
    "    \n",
    "    for idx in range(label_number):\n",
    "        label_set[idx] = struct.unpack('>B', file.read(1))\n",
    "\n",
    "    return label_set\n",
    "\n",
    "\n",
    "def ReLU(array): #if x<0 y=0 ; if x>0 y=x \n",
    "    value=np.multiply( np.add(array,np.abs(array)),0.5 )\n",
    "    return value\n",
    "\n",
    "\n",
    "def D_ReLU(array): #if x<0 y=0 ; if x>0 y=1                  #ReLU的backpropagation\n",
    "    value=np.multiply( np.add(array,np.abs(array)),0.5 )\n",
    "    value=np.multiply(value,np.reciprocal(array+1e-7))\n",
    "    return value\n",
    "\n",
    "\n",
    "def Onehot_encode(index, total):\n",
    "    encode = np.zeros((1,total))       #將矩陣拉成長條的\n",
    "    encode[0,index] = 1\n",
    "    return encode\n",
    "\n",
    "\n",
    "def Softmax(array): #e^x/sum(e^x)\n",
    "    array = array - np.max(array) # avoid overflow\n",
    "    Output=np.exp(array)\n",
    "    recipSum=np.reciprocal( np.sum(Output) )\n",
    "    Output=np.multiply(Output,recipSum)\n",
    "    return Output\n",
    "\n",
    "\n",
    "all_image = read_MNIST_image()\n",
    "all_label = read_MNIST_label()\n",
    "\n",
    "\n",
    "# Train:5500 Validate:500 Test:not include\n",
    "# You can select the index to do \"cross-validation\"\n",
    "# eg: train = all_image[:5000] + all_image[10000:60000]\n",
    "#     test  = all_image[5000:10000]\n",
    "\n",
    "train_image = all_image[:55000]\n",
    "train_label = all_label[:55000]\n",
    "test_image = all_image[55000:]\n",
    "test_label = all_label[55000:]\n",
    "\n",
    "\n",
    "\n",
    "# initialize NN weight sample from the \"standard normal\" distribution\n",
    "layer1W= np.random.randn(784,1024)*0.01\n",
    "OutputW= np.random.randn(1024,10)*0.01\n",
    "layer1b= np.random.randn(1024)*0.01\n",
    "Outputb= np.random.randn(10)*0.01\n",
    "\n",
    "\n",
    "\n",
    "# Iteration\n",
    "max_iteration = 1000    # hyperparameter \n",
    "batch_size = 16       # hyperparameter \n",
    "learning_rate = 0.00001  # hyperparameter \n",
    "\n",
    "train_size = train_image.shape[0]\n",
    "for it in range(max_iteration):\n",
    "    #print(\"Iteration: %d\"%it)\n",
    "\n",
    "    # Get batch\n",
    "    batch_index = np.random.choice(train_size, size=batch_size, replace=False)\n",
    "    batchX = np.zeros((0,784))\n",
    "    batchY = np.zeros((0,10))\n",
    "    for idx in batch_index:\n",
    "        batchX = np.vstack( (batchX, train_image[idx].flatten()) )\n",
    "        batchY = np.vstack( (batchY, Onehot_encode(train_label[idx], 10)) )\n",
    "    \n",
    "    # forward propagation\n",
    "    z1 = np.dot(batchX, layer1W) + layer1b #16*1024\n",
    "    Z = ReLU(z1)\n",
    "    #print(Z)\n",
    "    z2 = np.dot(Z, OutputW) + Outputb\n",
    "    for idx in range(batch_size):\n",
    "        z2[idx] = Softmax(z2[idx]) ##每1張圖分別做softmax\n",
    "    prob = z2\n",
    "    # Backpropagation\n",
    "    '''TODO: YOUR CODE '''\n",
    "   \n",
    "    #output layer\n",
    "    dZ = prob - batchY #16*10\n",
    "    dOutputW = np.dot(Z.T, dZ) #1024*10\n",
    "    dOutputb = np.sum(dZ, axis=0)/dZ.shape[0]\n",
    "   \n",
    "    #hiddeen layer\n",
    "    tmp = np.dot(OutputW, dZ.T) #1024*16\n",
    "    dZ1 = np.multiply(tmp.T, D_ReLU(z1)) \n",
    "    dlayer1W = np.dot(batchX.T, dZ1)\n",
    "    dlayer1b = np.sum(dZ1, axis=0)/dZ1.shape[0]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#     print(\"layer1W:\" , layer1W)\n",
    "#     print(\"layer1b:\" , layer1b)\n",
    "#     print(\"OutputW:\" , OutputW)\n",
    "#     print(\"Outputb:\" , Outputb)\n",
    "\n",
    "    layer1W = layer1W - learning_rate * dlayer1W\n",
    "    layer1b = layer1b - learning_rate * dlayer1b\n",
    "    OutputW = OutputW - learning_rate * dOutputW\n",
    "    Outputb = Outputb - learning_rate * dOutputb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy: 0.932200 \n"
     ]
    }
   ],
   "source": [
    "# Validate\n",
    "test_size = test_image.shape[0]\n",
    "\n",
    "testX = test_image.reshape(-1,784)\n",
    "testY = np.zeros((test_size,10))\n",
    "\n",
    "\n",
    "# print(testX.shape)\n",
    "for num in range(test_size):\n",
    "    testY[num] = Onehot_encode(test_label[num],10)\n",
    "\n",
    "# Forward propagation\n",
    "'''TODO: YOUR CODE'''\n",
    "z1 = np.dot(testX, layer1W) + layer1b #16*1024\n",
    "Z = ReLU(z1)\n",
    "\n",
    "z2 = np.dot(Z, OutputW) + Outputb\n",
    "for idx in range(test_size):\n",
    "    z2[idx] = Softmax(z2[idx]) ##每1張圖分別做softmax\n",
    "output = z2\n",
    "\n",
    "''' Random guess: you an do better than this !! '''\n",
    "\n",
    "predict = np.argmax(output, axis=1)\n",
    "answer = np.argmax(testY, axis=1)\n",
    "\n",
    "accuarcy = np.sum(np.equal(predict, answer)/test_size)\n",
    "print(\"Accuarcy: %f \"%accuarcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
